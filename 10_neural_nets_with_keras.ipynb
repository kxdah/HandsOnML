{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_neural_nets_with_keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPiNP3ZAvKg6XjkqZfRPl68",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rpdahxn/HandsOnML/blob/main/10_neural_nets_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2JrdjHBO-T7V"
      },
      "outputs": [],
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# 텐서플로 ≥2.0 필수\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.3.1 퍼셉트론"
      ],
      "metadata": {
        "id": "uP8Fc24n-u9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런은 하나의 TLU 네트워크를 구현한 Perceptron 클래스를 제공한다.\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, (2, 3)]  # 꽃잎의 길이와 너비\n",
        "y = (iris.target == 0).astype(np.int)  # Iris Setosa 인가?\n",
        "\n",
        "per_clf = Perceptron()\n",
        "per_clf.fit(X, y)\n",
        "\n",
        "y_pred = per_clf.predict([[2, 0.5]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNskHoea-k5p",
        "outputId": "892e952a-e388-4c8e-9997-a55ce635caaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cJJ-jhn_amp",
        "outputId": "f6d2b33d-b0f8-422b-a8af-f5d574d50d26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmtbxztq_rbF",
        "outputId": "7326d3d0-8a19-4d64-b4c1-2b43e3fcd89a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hd5W4oeEEonQ",
        "outputId": "9e53f5b4-bb10-4fa3-da32-e699b0862731"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.8.0'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2.2 시퀀셜 API를 사용하여 이미지 분류기 만들기  \n",
        "**케라스를 사용하여 데이터셋 적재하기**"
      ],
      "metadata": {
        "id": "EFUD_grjE00n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GAbfPy6EwGz",
        "outputId": "92ccdfbc-0087-47cc-b7b7-e0b786de960c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWj9pabmFV2d",
        "outputId": "3ecf5df8-26b7-4414-8beb-5442c30debca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__pbXjodFaGF",
        "outputId": "4713603b-0903-4b4f-b78d-0b25d5ae16cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "검증 세트를 만든다.  \n",
        "경사 하강법으로 신경망을 훈련하기 때문에 입력 특성의 스케일을 조정한다."
      ],
      "metadata": {
        "id": "ZWRLMWuaFjfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0  # 픽셀 강도를 255로 나눠서 0~1 범위의 실수로 바꾼다.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "7Axvk-k0FcdD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0], cmap = \"binary\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "SqITWZV_GEZO",
        "outputId": "1cad3ab7-e10b-43bc-f474-fb73f17966ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "KiAAkY4nGP8y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[y_train[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sEzODdGhGhyN",
        "outputId": "d3138bd6-bd2c-4c56-9723-70a70e7e1a42"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Coat'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**시퀀셜 API를 사용하여 모델 만들기**  "
      ],
      "metadata": {
        "id": "4_u2zKCSGo8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 개의 은닉층으로 이루어진 분류용 다층 퍼셉트론\n",
        "# 방법1\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape = [28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation = \"relu\"))\n",
        "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
        "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "a70IZp9eGlAd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "81YZYtI1HGtp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 방법 2\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape = [28, 28]),\n",
        "    keras.layers.Dense(300, activation = \"relu\"),\n",
        "    keras.layers.Dense(100, activation = \"relu\"),\n",
        "    keras.layers.Dense(10, activation = \"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "x5zwXTLKHhRy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "god6u7irH8UK",
        "outputId": "1b175637-79fc-4c51-fda7-892aed46caf9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5OeazIYILp7",
        "outputId": "7ba303f0-16d0-4f2b-ccee-7142c7ab6a10"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.core.flatten.Flatten at 0x7f10404ee950>,\n",
              " <keras.layers.core.dense.Dense at 0x7f10404ee8d0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f10404e8cd0>,\n",
              " <keras.layers.core.dense.Dense at 0x7f10404e8e50>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden1 = model.layers[1]"
      ],
      "metadata": {
        "id": "gvwlHV_9Ibe5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_layer('dense') is hidden1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTnLtotzIkQB",
        "outputId": "fb1ffc4d-302f-48a3-da2b-6858860f28c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = hidden1.get_weights()"
      ],
      "metadata": {
        "id": "WmrvOnISInE6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck3VQ2DRIu1z",
        "outputId": "ca08bb43-5713-4c60-dd52-9bf699f6352b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
              "         0.03859074, -0.06889391],\n",
              "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
              "        -0.02763776, -0.04165364],\n",
              "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
              "         0.07121518, -0.07331658],\n",
              "       ...,\n",
              "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
              "         0.00228987,  0.05581069],\n",
              "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
              "         0.00034875,  0.02878492],\n",
              "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
              "         0.00272203, -0.06793761]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(weights.shape)\n",
        "print(biases)\n",
        "print(biases.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yEYp0enIvp1",
        "outputId": "0b1c9138-fc3a-4d53-c1f4-716335e27c4d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 300)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 컴파일**"
      ],
      "metadata": {
        "id": "PK-BMnFQmXZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
        "              optimizer = \"sgd\",\n",
        "              metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "qV-Rj4CbmWYO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 훈련과 평가**"
      ],
      "metadata": {
        "id": "4AMEFMhSm9JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 30,\n",
        "                    validation_data = (X_valid, y_valid))"
      ],
      "metadata": {
        "id": "7d41G-Dwm8b3",
        "outputId": "5dc07946-66a4-4333-9092-c3f8bb64068c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 10s 4ms/step - loss: 0.7237 - accuracy: 0.7643 - val_loss: 0.5213 - val_accuracy: 0.8226\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4842 - accuracy: 0.8317 - val_loss: 0.4351 - val_accuracy: 0.8538\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4392 - accuracy: 0.8457 - val_loss: 0.5327 - val_accuracy: 0.7992\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4124 - accuracy: 0.8565 - val_loss: 0.3917 - val_accuracy: 0.8646\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3940 - accuracy: 0.8624 - val_loss: 0.3743 - val_accuracy: 0.8684\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3752 - accuracy: 0.8677 - val_loss: 0.3712 - val_accuracy: 0.8726\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3632 - accuracy: 0.8712 - val_loss: 0.3612 - val_accuracy: 0.8720\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3515 - accuracy: 0.8750 - val_loss: 0.3852 - val_accuracy: 0.8616\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3412 - accuracy: 0.8791 - val_loss: 0.3587 - val_accuracy: 0.8694\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3318 - accuracy: 0.8823 - val_loss: 0.3414 - val_accuracy: 0.8784\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3239 - accuracy: 0.8835 - val_loss: 0.3442 - val_accuracy: 0.8776\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3147 - accuracy: 0.8867 - val_loss: 0.3306 - val_accuracy: 0.8818\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3079 - accuracy: 0.8896 - val_loss: 0.3283 - val_accuracy: 0.8880\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3020 - accuracy: 0.8913 - val_loss: 0.3427 - val_accuracy: 0.8762\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2944 - accuracy: 0.8940 - val_loss: 0.3222 - val_accuracy: 0.8840\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2889 - accuracy: 0.8969 - val_loss: 0.3094 - val_accuracy: 0.8896\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2838 - accuracy: 0.8976 - val_loss: 0.3554 - val_accuracy: 0.8720\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2776 - accuracy: 0.9003 - val_loss: 0.3124 - val_accuracy: 0.8926\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2726 - accuracy: 0.9024 - val_loss: 0.3133 - val_accuracy: 0.8906\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2672 - accuracy: 0.9036 - val_loss: 0.3295 - val_accuracy: 0.8802\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2623 - accuracy: 0.9055 - val_loss: 0.3047 - val_accuracy: 0.8920\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2574 - accuracy: 0.9077 - val_loss: 0.2960 - val_accuracy: 0.8970\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2534 - accuracy: 0.9086 - val_loss: 0.2972 - val_accuracy: 0.8934\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2484 - accuracy: 0.9103 - val_loss: 0.3093 - val_accuracy: 0.8882\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2440 - accuracy: 0.9126 - val_loss: 0.2968 - val_accuracy: 0.8948\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2403 - accuracy: 0.9140 - val_loss: 0.3069 - val_accuracy: 0.8902\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2361 - accuracy: 0.9156 - val_loss: 0.3026 - val_accuracy: 0.8956\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2323 - accuracy: 0.9170 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2281 - accuracy: 0.9187 - val_loss: 0.3046 - val_accuracy: 0.8906\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2246 - accuracy: 0.9196 - val_loss: 0.3030 - val_accuracy: 0.8916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize = (8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qY1y6I5PnHMp",
        "outputId": "78f1f132-8773-4ec6-e090-40c8a263c698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "lh0iFr9kobpM",
        "outputId": "c84464c9-12b7-464b-953c-cfdd66c20b39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3369 - accuracy: 0.8826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3369462788105011, 0.8826000094413757]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델을 사용해 예측을 만들기**"
      ],
      "metadata": {
        "id": "srkjvFqFoguq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_test)\n",
        "y_proba.round(2)"
      ],
      "metadata": {
        "id": "IiYr2tIloekj",
        "outputId": "3e9992ef-b3b9-4024-9e17-5d7659d02f09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , ..., 0.02, 0.  , 0.96],\n",
              "       [0.  , 0.  , 0.99, ..., 0.  , 0.  , 0.  ],\n",
              "       [0.  , 1.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
              "       ...,\n",
              "       [0.01, 0.  , 0.  , ..., 0.  , 0.98, 0.  ],\n",
              "       [0.  , 1.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 높은 확률을 가진 클래스에만 관심이 있다면\n",
        "y_pred = np.argmax(model.predict(X_new), axis = 1)\n",
        "np.array(class_names)[y_pred]"
      ],
      "metadata": {
        "id": "oPT7JLidopRZ",
        "outputId": "087bfcd6-7195-41dc-c2b3-dec04b7ce2eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_new = y_test[:3]\n",
        "y_new"
      ],
      "metadata": {
        "id": "b71LW5rho9c5",
        "outputId": "3b5e0513-9fb9-41c0-a285-5e99ba406a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2.3 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기"
      ],
      "metadata": {
        "id": "pET0TdWdpPu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.fit_transform(X_valid)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "C0G4g2QWpL6S"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "      keras.layers.Dense(30, activation = \"relu\", input_shape = X_train.shape[1:]),\n",
        "      keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss = \"mean_squared_error\", optimizer = \"sgd\")\n",
        "history = model.fit(X_train, y_train, epochs = 20,\n",
        "                    validation_data = (X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)"
      ],
      "metadata": {
        "id": "yPBomi8Rp2D_",
        "outputId": "d2e4f8cf-5ba4-498e-bca1-867e2b039715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 4s 8ms/step - loss: 0.7987 - val_loss: 0.7527\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.5335 - val_loss: 0.6154\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.6129 - val_loss: 0.5031\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.4694 - val_loss: 0.4783\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.4462 - val_loss: 0.4613\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.4350 - val_loss: 0.4578\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.4263 - val_loss: 0.4457\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 2s 7ms/step - loss: 0.4182 - val_loss: 0.4504\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.4116 - val_loss: 0.4361\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.4080 - val_loss: 0.4305\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.4025 - val_loss: 0.4273\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.3981 - val_loss: 0.4292\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.3949 - val_loss: 0.4347\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.3910 - val_loss: 0.4322\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.3874 - val_loss: 0.4312\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.3856 - val_loss: 0.4141\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.3825 - val_loss: 0.4228\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.3786 - val_loss: 0.4143\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.3765 - val_loss: 0.4111\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.3744 - val_loss: 0.4074\n",
            "162/162 [==============================] - 1s 3ms/step - loss: 1.5050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2.4 함수형 API를 사용해 복잡한 모델 만들기"
      ],
      "metadata": {
        "id": "53SxL_Gnqy8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
        "hidden1 = keras.layers.Dense(30, activation = \"relu\")(input_)\n",
        "hidden2 = keras.layers.Dense(30, activation = \"relu\")(hidden1)\n",
        "concat = keras.layers.Concatenate()([input_, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.Model(inputs= [input_], outputs = [output])"
      ],
      "metadata": {
        "id": "8-Otk-JRqqJm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_A = keras.layers.Input(shape = [5], name = \"wide_input\")\n",
        "input_B = keras.layers.Input(shape = [6], name = \"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation = \"relu\")(input_A)\n",
        "hidden2 = keras.layers.Dense(30, activation = \"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name = \"output\")(concat)\n",
        "model = keras.Model(inputs = [input_A, input_B], outputs = [output])"
      ],
      "metadata": {
        "id": "vTTjOid1ra4O"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "model.compile(loss = \"mse\", optimizer = keras.optimizers.SGD(lr = 1e-3))\n",
        "\n",
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B= X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "\n",
        "history = model.fit((X_train_A, X_train_B), y_train, epochs = 20,\n",
        "                    validation_data = ((X_valid_A, X_valid_B), y_valid))\n",
        "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
        "y_pred = model.predict((X_new_A, X_new_B))"
      ],
      "metadata": {
        "id": "qNGSr6LJscyv",
        "outputId": "b0fc59de-c219-477a-821a-f0eba98f9252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "363/363 [==============================] - 4s 9ms/step - loss: 1.8534 - val_loss: 0.8032\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.7540 - val_loss: 0.7481\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.7156 - val_loss: 0.7237\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6918 - val_loss: 0.7029\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6723 - val_loss: 0.6862\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6563 - val_loss: 0.6720\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6438 - val_loss: 0.6632\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6326 - val_loss: 0.6521\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6230 - val_loss: 0.6444\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6147 - val_loss: 0.6387\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6070 - val_loss: 0.6316\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.6005 - val_loss: 0.6274\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.5945 - val_loss: 0.6246\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.5892 - val_loss: 0.6175\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.5840 - val_loss: 0.6141\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.5799 - val_loss: 0.6117\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.5757 - val_loss: 0.6089\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.5722 - val_loss: 0.6079\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.5691 - val_loss: 0.6024\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.5661 - val_loss: 0.6011\n",
            "162/162 [==============================] - 1s 5ms/step - loss: 0.5778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "규제를 위한 보조 출력 추가하기"
      ],
      "metadata": {
        "id": "u3-JvN_sv0Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_A = keras.layers.Input(shape = [5], name = \"wide_input\")\n",
        "input_B = keras.layers.Input(shape = [6], name = \"deep_input\")\n",
        "hidden1 = keras.layers.Dense(30, activation = \"relu\")(input_A)\n",
        "hidden2 = keras.layers.Dense(30, activation = \"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name = \"main_output\")(concat)\n",
        "aux_output = keras.layers.Dense(1, name = \"aux_output\")(hidden2)\n",
        "model = keras.Model(inputs = [input_A, input_B], outputs = [output, aux_output])"
      ],
      "metadata": {
        "id": "M4czwkhzvWUc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = [\"mse\", \"mse\"], loss_weights = [0.9, 0.1], optimizer = \"sgd\")"
      ],
      "metadata": {
        "id": "lVyNFdfVwG2d"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    [X_train_A, X_train_B], [y_train, y_train], epochs = 20,\n",
        "    validation_data = ([X_valid_A, X_valid_B], [y_valid, y_valid])\n",
        ")"
      ],
      "metadata": {
        "id": "WZ-2ZmjPwVNb",
        "outputId": "422e4e3b-cccc-4210-a49e-543788471166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 6s 12ms/step - loss: 0.9258 - main_output_loss: 0.8379 - aux_output_loss: 1.7172 - val_loss: 0.6407 - val_main_output_loss: 0.6277 - val_aux_output_loss: 0.7578\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5902 - main_output_loss: 0.5792 - aux_output_loss: 0.6887 - val_loss: 0.6038 - val_main_output_loss: 0.5973 - val_aux_output_loss: 0.6624\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5621 - main_output_loss: 0.5552 - aux_output_loss: 0.6242 - val_loss: 0.5913 - val_main_output_loss: 0.5864 - val_aux_output_loss: 0.6357\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 4s 11ms/step - loss: 0.5514 - main_output_loss: 0.5459 - aux_output_loss: 0.6000 - val_loss: 0.5825 - val_main_output_loss: 0.5786 - val_aux_output_loss: 0.6183\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 4s 12ms/step - loss: 0.5436 - main_output_loss: 0.5392 - aux_output_loss: 0.5833 - val_loss: 0.5829 - val_main_output_loss: 0.5800 - val_aux_output_loss: 0.6085\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5378 - main_output_loss: 0.5338 - aux_output_loss: 0.5736 - val_loss: 0.5736 - val_main_output_loss: 0.5703 - val_aux_output_loss: 0.6036\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 4s 11ms/step - loss: 0.5314 - main_output_loss: 0.5277 - aux_output_loss: 0.5647 - val_loss: 0.5672 - val_main_output_loss: 0.5640 - val_aux_output_loss: 0.5961\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5269 - main_output_loss: 0.5234 - aux_output_loss: 0.5586 - val_loss: 0.5688 - val_main_output_loss: 0.5662 - val_aux_output_loss: 0.5920\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5224 - main_output_loss: 0.5190 - aux_output_loss: 0.5530 - val_loss: 0.5594 - val_main_output_loss: 0.5565 - val_aux_output_loss: 0.5853\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 3s 10ms/step - loss: 0.5198 - main_output_loss: 0.5166 - aux_output_loss: 0.5489 - val_loss: 0.5507 - val_main_output_loss: 0.5473 - val_aux_output_loss: 0.5808\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5156 - main_output_loss: 0.5123 - aux_output_loss: 0.5445 - val_loss: 0.5538 - val_main_output_loss: 0.5509 - val_aux_output_loss: 0.5803\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5134 - main_output_loss: 0.5103 - aux_output_loss: 0.5412 - val_loss: 0.5550 - val_main_output_loss: 0.5524 - val_aux_output_loss: 0.5778\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.5109 - main_output_loss: 0.5079 - aux_output_loss: 0.5380 - val_loss: 0.5533 - val_main_output_loss: 0.5506 - val_aux_output_loss: 0.5779\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 4s 12ms/step - loss: 0.5093 - main_output_loss: 0.5064 - aux_output_loss: 0.5351 - val_loss: 0.5567 - val_main_output_loss: 0.5550 - val_aux_output_loss: 0.5722\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5073 - main_output_loss: 0.5045 - aux_output_loss: 0.5327 - val_loss: 0.5608 - val_main_output_loss: 0.5588 - val_aux_output_loss: 0.5787\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5059 - main_output_loss: 0.5032 - aux_output_loss: 0.5304 - val_loss: 0.5423 - val_main_output_loss: 0.5394 - val_aux_output_loss: 0.5683\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 4s 11ms/step - loss: 0.5051 - main_output_loss: 0.5025 - aux_output_loss: 0.5286 - val_loss: 0.5441 - val_main_output_loss: 0.5413 - val_aux_output_loss: 0.5692\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5030 - main_output_loss: 0.5003 - aux_output_loss: 0.5267 - val_loss: 0.5373 - val_main_output_loss: 0.5343 - val_aux_output_loss: 0.5642\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 4s 12ms/step - loss: 0.5021 - main_output_loss: 0.4996 - aux_output_loss: 0.5246 - val_loss: 0.5363 - val_main_output_loss: 0.5334 - val_aux_output_loss: 0.5626\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 4s 11ms/step - loss: 0.5004 - main_output_loss: 0.4979 - aux_output_loss: 0.5226 - val_loss: 0.5376 - val_main_output_loss: 0.5351 - val_aux_output_loss: 0.5606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 평가하면 개별 손실과 함께 총 손실을 반환한다.\n",
        "total_loss, main_loss, aux_loss = model.evaluate(\n",
        "    [X_test_A, X_test_B], [y_test, y_test]\n",
        ")"
      ],
      "metadata": {
        "id": "i7oB6x5qwv0-",
        "outputId": "dccfb267-54b8-4c7d-dec3-d2eb27edc73b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 6ms/step - loss: 0.5220 - main_output_loss: 0.5191 - aux_output_loss: 0.5480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
      ],
      "metadata": {
        "id": "ITSjhqsQxCRY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2.5 서브클래싱 API로 동적 모델 만들기"
      ],
      "metadata": {
        "id": "3GNktnFsxNi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WideAndDeepModel(keras.models.Model):\n",
        "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
        "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
        "        self.main_output = keras.layers.Dense(1)\n",
        "        self.aux_output = keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        input_A, input_B = inputs\n",
        "        hidden1 = self.hidden1(input_B)\n",
        "        hidden2 = self.hidden2(hidden1)\n",
        "        concat = keras.layers.concatenate([input_A, hidden2])\n",
        "        main_output = self.main_output(concat)\n",
        "        aux_output = self.aux_output(hidden2)\n",
        "        return main_output, aux_output\n",
        "\n",
        "model = WideAndDeepModel(30, activation=\"relu\")"
      ],
      "metadata": {
        "id": "DsDZz4oNxIBT"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2.6 모델 저장과 복원"
      ],
      "metadata": {
        "id": "ExX1WANVzPn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "]) "
      ],
      "metadata": {
        "id": "cTmHFArQxvzi"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "eCTDqNMizbz2",
        "outputId": "54b05ca1-7cc4-49f8-a599-dbc6be18826f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 4s 9ms/step - loss: 1.6711 - val_loss: 0.9434\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.8232 - val_loss: 0.7680\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 2s 7ms/step - loss: 0.7207 - val_loss: 0.6953\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.6605 - val_loss: 0.6431\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.6153 - val_loss: 0.6020\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 4s 10ms/step - loss: 0.5791 - val_loss: 0.5728\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 3s 9ms/step - loss: 0.5499 - val_loss: 0.5485\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.5257 - val_loss: 0.5287\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.5062 - val_loss: 0.5134\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4908 - val_loss: 0.5024\n",
            "162/162 [==============================] - 1s 7ms/step - loss: 0.4419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my_keras_model.h5\")"
      ],
      "metadata": {
        "id": "mWJV7DkfzgXI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_keras_model.h5\")"
      ],
      "metadata": {
        "id": "3iMbM3_rzk1C"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_new)"
      ],
      "metadata": {
        "id": "ru6CkiaazoRY",
        "outputId": "2120b7cd-69d5-4cfc-8311-e86cf466bfca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 318 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0fc8303050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.92301965],\n",
              "       [1.5977337 ],\n",
              "       [3.6362894 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"my_keras_weights.ckpt\")"
      ],
      "metadata": {
        "id": "S336TOYNzyDO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"my_keras_weights.ckpt\")"
      ],
      "metadata": {
        "id": "KrJgCeZVz1TT",
        "outputId": "e7b0c08a-6705-467a-fcef-c448584eb1b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0fc82b6a90>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.2.7 콜백 사용하기"
      ],
      "metadata": {
        "id": "iwagJSHwz7p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "Jmf3wfmWz4NZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    "
      ],
      "metadata": {
        "id": "5dcqvH5K0Iwd"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"mse\", optimizer = keras.optimizers.SGD(learning_rate = 1e-3))\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only = \"True\")\n",
        "history = model.fit(X_train, y_train, epochs = 10, callbacks = [checkpoint_cb])"
      ],
      "metadata": {
        "id": "dGVlp4TF0NUh",
        "outputId": "725dd53d-d403-48f0-8b88-5211c16bffb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "361/363 [============================>.] - ETA: 0s - loss: 0.4847WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.4845\n",
            "Epoch 2/10\n",
            "359/363 [============================>.] - ETA: 0s - loss: 0.4770WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "363/363 [==============================] - 2s 7ms/step - loss: 0.4765\n",
            "Epoch 3/10\n",
            "357/363 [============================>.] - ETA: 0s - loss: 0.4707WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "363/363 [==============================] - 2s 7ms/step - loss: 0.4693\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - ETA: 0s - loss: 0.4629WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4629\n",
            "Epoch 5/10\n",
            "359/363 [============================>.] - ETA: 0s - loss: 0.4575WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4575\n",
            "Epoch 6/10\n",
            "358/363 [============================>.] - ETA: 0s - loss: 0.4532WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4520\n",
            "Epoch 7/10\n",
            "362/363 [============================>.] - ETA: 0s - loss: 0.4475WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4476\n",
            "Epoch 8/10\n",
            "362/363 [============================>.] - ETA: 0s - loss: 0.4434WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "363/363 [==============================] - 2s 7ms/step - loss: 0.4432\n",
            "Epoch 9/10\n",
            "358/363 [============================>.] - ETA: 0s - loss: 0.4382WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "363/363 [==============================] - 3s 7ms/step - loss: 0.4393\n",
            "Epoch 10/10\n",
            "355/363 [============================>.] - ETA: 0s - loss: 0.4338WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "363/363 [==============================] - 2s 7ms/step - loss: 0.4362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_keras_model.h5\")\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "ju2tRqJH0gmv",
        "outputId": "2960de5a-c05f-4f00-a2ac-2aa2a35a32a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 1s 5ms/step - loss: 0.4478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                  restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=100,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "LQPfWaKZ003Y",
        "outputId": "3b123bea-f118-47e1-cca5-b6df25314ba8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "363/363 [==============================] - 4s 9ms/step - loss: 0.4845 - val_loss: 0.4950\n",
            "Epoch 2/100\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4765 - val_loss: 0.4867\n",
            "Epoch 3/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4693 - val_loss: 0.4808\n",
            "Epoch 4/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4629 - val_loss: 0.4776\n",
            "Epoch 5/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4575 - val_loss: 0.4716\n",
            "Epoch 6/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4520 - val_loss: 0.4700\n",
            "Epoch 7/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4476 - val_loss: 0.4661\n",
            "Epoch 8/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4432 - val_loss: 0.4624\n",
            "Epoch 9/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4393 - val_loss: 0.4589\n",
            "Epoch 10/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4362 - val_loss: 0.4571\n",
            "Epoch 11/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4329 - val_loss: 0.4542\n",
            "Epoch 12/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4301 - val_loss: 0.4525\n",
            "Epoch 13/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4273 - val_loss: 0.4512\n",
            "Epoch 14/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4246 - val_loss: 0.4482\n",
            "Epoch 15/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4219 - val_loss: 0.4470\n",
            "Epoch 16/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4197 - val_loss: 0.4449\n",
            "Epoch 17/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4174 - val_loss: 0.4442\n",
            "Epoch 18/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4155 - val_loss: 0.4425\n",
            "Epoch 19/100\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4134 - val_loss: 0.4400\n",
            "Epoch 20/100\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.4115 - val_loss: 0.4388\n",
            "Epoch 21/100\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4099 - val_loss: 0.4376\n",
            "Epoch 22/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4080 - val_loss: 0.4367\n",
            "Epoch 23/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4063 - val_loss: 0.4357\n",
            "Epoch 24/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4048 - val_loss: 0.4335\n",
            "Epoch 25/100\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.4032 - val_loss: 0.4331\n",
            "Epoch 26/100\n",
            "363/363 [==============================] - 2s 6ms/step - loss: 0.4018 - val_loss: 0.4329\n",
            "Epoch 27/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.4003 - val_loss: 0.4311\n",
            "Epoch 28/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3991 - val_loss: 0.4286\n",
            "Epoch 29/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3977 - val_loss: 0.4294\n",
            "Epoch 30/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3963 - val_loss: 0.4271\n",
            "Epoch 31/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3948 - val_loss: 0.4257\n",
            "Epoch 32/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3938 - val_loss: 0.4276\n",
            "Epoch 33/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3923 - val_loss: 0.4261\n",
            "Epoch 34/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3912 - val_loss: 0.4235\n",
            "Epoch 35/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3902 - val_loss: 0.4233\n",
            "Epoch 36/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3891 - val_loss: 0.4230\n",
            "Epoch 37/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3881 - val_loss: 0.4209\n",
            "Epoch 38/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3874 - val_loss: 0.4202\n",
            "Epoch 39/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3860 - val_loss: 0.4204\n",
            "Epoch 40/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3852 - val_loss: 0.4190\n",
            "Epoch 41/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3841 - val_loss: 0.4175\n",
            "Epoch 42/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3829 - val_loss: 0.4171\n",
            "Epoch 43/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3816 - val_loss: 0.4170\n",
            "Epoch 44/100\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.3812 - val_loss: 0.4167\n",
            "Epoch 45/100\n",
            "363/363 [==============================] - 3s 8ms/step - loss: 0.3801 - val_loss: 0.4159\n",
            "Epoch 46/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3793 - val_loss: 0.4135\n",
            "Epoch 47/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3783 - val_loss: 0.4128\n",
            "Epoch 48/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3771 - val_loss: 0.4134\n",
            "Epoch 49/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3760 - val_loss: 0.4148\n",
            "Epoch 50/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3755 - val_loss: 0.4109\n",
            "Epoch 51/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3742 - val_loss: 0.4123\n",
            "Epoch 52/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3738 - val_loss: 0.4104\n",
            "Epoch 53/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3728 - val_loss: 0.4093\n",
            "Epoch 54/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3720 - val_loss: 0.4090\n",
            "Epoch 55/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3710 - val_loss: 0.4080\n",
            "Epoch 56/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3702 - val_loss: 0.4073\n",
            "Epoch 57/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3695 - val_loss: 0.4072\n",
            "Epoch 58/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3687 - val_loss: 0.4045\n",
            "Epoch 59/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3677 - val_loss: 0.4046\n",
            "Epoch 60/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3672 - val_loss: 0.4055\n",
            "Epoch 61/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3661 - val_loss: 0.4037\n",
            "Epoch 62/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3653 - val_loss: 0.4062\n",
            "Epoch 63/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3647 - val_loss: 0.4026\n",
            "Epoch 64/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3635 - val_loss: 0.4020\n",
            "Epoch 65/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3627 - val_loss: 0.4014\n",
            "Epoch 66/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3617 - val_loss: 0.4013\n",
            "Epoch 67/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3613 - val_loss: 0.3994\n",
            "Epoch 68/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3602 - val_loss: 0.4011\n",
            "Epoch 69/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3595 - val_loss: 0.4004\n",
            "Epoch 70/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3589 - val_loss: 0.3993\n",
            "Epoch 71/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3578 - val_loss: 0.3979\n",
            "Epoch 72/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3575 - val_loss: 0.3966\n",
            "Epoch 73/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3560 - val_loss: 0.3970\n",
            "Epoch 74/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3558 - val_loss: 0.3960\n",
            "Epoch 75/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3547 - val_loss: 0.3955\n",
            "Epoch 76/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3542 - val_loss: 0.3940\n",
            "Epoch 77/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3534 - val_loss: 0.3940\n",
            "Epoch 78/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3527 - val_loss: 0.3937\n",
            "Epoch 79/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3520 - val_loss: 0.3931\n",
            "Epoch 80/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3510 - val_loss: 0.3923\n",
            "Epoch 81/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3501 - val_loss: 0.3930\n",
            "Epoch 82/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3501 - val_loss: 0.3935\n",
            "Epoch 83/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3492 - val_loss: 0.3914\n",
            "Epoch 84/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3486 - val_loss: 0.3917\n",
            "Epoch 85/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3476 - val_loss: 0.3905\n",
            "Epoch 86/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3473 - val_loss: 0.3919\n",
            "Epoch 87/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3465 - val_loss: 0.3918\n",
            "Epoch 88/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3461 - val_loss: 0.3917\n",
            "Epoch 89/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3449 - val_loss: 0.3909\n",
            "Epoch 90/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3451 - val_loss: 0.3885\n",
            "Epoch 91/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3441 - val_loss: 0.3879\n",
            "Epoch 92/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3438 - val_loss: 0.3896\n",
            "Epoch 93/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3432 - val_loss: 0.3888\n",
            "Epoch 94/100\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3425 - val_loss: 0.3869\n",
            "Epoch 95/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3418 - val_loss: 0.3882\n",
            "Epoch 96/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3414 - val_loss: 0.3892\n",
            "Epoch 97/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3409 - val_loss: 0.3868\n",
            "Epoch 98/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3413 - val_loss: 0.3869\n",
            "Epoch 99/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3397 - val_loss: 0.3858\n",
            "Epoch 100/100\n",
            "363/363 [==============================] - 2s 4ms/step - loss: 0.3397 - val_loss: 0.3847\n",
            "162/162 [==============================] - 0s 3ms/step - loss: 1.4331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 정의 콜백\n",
        "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
      ],
      "metadata": {
        "id": "L3c4GT5J1JsN"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YkST1fvs1cNV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}